{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZBEJmZtJInu"
      },
      "source": [
        "# Creating a new tree in main branch when question goes out of context - FINAL WORKING CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0QSTLeUJIJH",
        "outputId": "b837dd57-a8d1-4f2c-cc4f-6231c0d69dc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added root node with id: 74b4e45d-ba62-41f7-a6f3-d93bcd922754\n",
            "Adding node under parent id 74b4e45d-ba62-41f7-a6f3-d93bcd922754.\n",
            "Added child node with id: 686cf5b3-77da-44bb-8cd8-7b7ff10d0b51 under parent id: 74b4e45d-ba62-41f7-a6f3-d93bcd922754\n",
            "Question out of context with parent id 74b4e45d-ba62-41f7-a6f3-d93bcd922754. Creating a new tree.\n",
            "Added node with id: 942e2c31-25ed-4e82-be61-5ac596c9c87e as a new tree due to context change from parent id: 74b4e45d-ba62-41f7-a6f3-d93bcd922754\n",
            "Adding node under parent id 686cf5b3-77da-44bb-8cd8-7b7ff10d0b51.\n",
            "Added grandchild node with id: 59eb16b6-3d04-47bf-a7a5-f01d7b5cc686 under parent id: 686cf5b3-77da-44bb-8cd8-7b7ff10d0b51\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import uuid\n",
        "import re\n",
        "\n",
        "# Define a set of common English stopwords to filter out during tokenization.\n",
        "STOPWORDS = {\n",
        "    \"what\", \"is\", \"your\", \"a\", \"an\", \"the\", \"and\", \"or\", \"but\", \"if\",\n",
        "    \"of\", \"for\", \"to\", \"in\", \"with\", \"on\", \"at\", \"from\", \"as\", \"it\",\n",
        "    \"are\", \"this\", \"that\", \"was\", \"were\", \"be\", \"been\", \"has\", \"have\", \"had\"\n",
        "}\n",
        "\n",
        "def find_node_by_id(nodes, node_id):\n",
        "    \"\"\"\n",
        "    Recursively searches for a node with the given node_id in a list of nodes.\n",
        "\n",
        "    Parameters:\n",
        "        nodes (list): A list of node dictionaries.\n",
        "        node_id (str): The unique identifier to search for.\n",
        "\n",
        "    Returns:\n",
        "        dict or None: The node dictionary if found; otherwise, None.\n",
        "    \"\"\"\n",
        "    for node in nodes:\n",
        "        if node['id'] == node_id:\n",
        "            return node\n",
        "        found = find_node_by_id(node.get('children', []), node_id)\n",
        "        if found:\n",
        "            return found\n",
        "    return None\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenizes the input text into a set of lower-case words, removing punctuation\n",
        "    and filtering out common stopwords.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The input text.\n",
        "\n",
        "    Returns:\n",
        "        set: A set of words with stopwords removed.\n",
        "    \"\"\"\n",
        "    tokens = set(re.findall(r'\\w+', text.lower()))\n",
        "    filtered_tokens = {token for token in tokens if token not in STOPWORDS}\n",
        "    return filtered_tokens\n",
        "\n",
        "def is_in_context(new_question, parent_node, threshold=0.2):\n",
        "    \"\"\"\n",
        "    Determines whether the new question is contextually relevant to the parent's content.\n",
        "\n",
        "    This heuristic computes the token overlap ratio after filtering out common stopwords.\n",
        "\n",
        "    Parameters:\n",
        "        new_question (str): The new question text.\n",
        "        parent_node (dict): The parent node containing 'question' and 'answer' keys.\n",
        "        threshold (float): The minimum fraction of common tokens required to consider the question in context.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the new question is in context, False otherwise.\n",
        "    \"\"\"\n",
        "    parent_text = parent_node.get('question', '') + \" \" + parent_node.get('answer', '')\n",
        "    new_tokens = tokenize(new_question)\n",
        "    parent_tokens = tokenize(parent_text)\n",
        "\n",
        "    if not new_tokens:\n",
        "        return False  # Avoid division by zero\n",
        "\n",
        "    common_tokens = new_tokens.intersection(parent_tokens)\n",
        "    ratio = len(common_tokens) / len(new_tokens)\n",
        "\n",
        "    return ratio >= threshold\n",
        "\n",
        "def update_json_tree(file_path, question, answer, parent_id=None):\n",
        "    \"\"\"\n",
        "    Dynamically updates a JSON file by adding a new node to a tree of question-answer pairs.\n",
        "\n",
        "    This function supports creating a new tree if the new question is determined to be out of context\n",
        "    relative to the intended parent node.\n",
        "\n",
        "    Each node in the tree contains:\n",
        "      - id: A unique identifier for the node.\n",
        "      - question: The question text.\n",
        "      - answer: The corresponding answer.\n",
        "      - children: A list of child nodes (subtree).\n",
        "\n",
        "    Parameters:\n",
        "        file_path (str): Path to the JSON file.\n",
        "        question (str): The question text to be added.\n",
        "        answer (str): The corresponding answer.\n",
        "        parent_id (str, optional): The unique identifier of the parent node. If None,\n",
        "                                   the new node is added as a root-level entry. If provided but the new question\n",
        "                                   is out of context with the parent's content, a new tree is started.\n",
        "\n",
        "    Returns:\n",
        "        str: The unique identifier of the newly added node.\n",
        "    \"\"\"\n",
        "    # Load existing tree data; initialize as an empty list if the file is absent or invalid.\n",
        "    if os.path.exists(file_path):\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                tree = json.load(f)\n",
        "                if not isinstance(tree, list):\n",
        "                    tree = []\n",
        "        except json.JSONDecodeError:\n",
        "            tree = []\n",
        "    else:\n",
        "        tree = []\n",
        "\n",
        "    # Create a new node with a unique identifier and an empty children list.\n",
        "    new_id = str(uuid.uuid4())\n",
        "    new_node = {\n",
        "        \"id\": new_id,\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"children\": []\n",
        "    }\n",
        "\n",
        "    # If a parent_id is provided, attempt to attach the new node as a child if in context.\n",
        "    if parent_id is not None:\n",
        "        parent_node = find_node_by_id(tree, parent_id)\n",
        "        if parent_node is not None:\n",
        "            if is_in_context(question, parent_node):\n",
        "                parent_node.setdefault(\"children\", []).append(new_node)\n",
        "                print(f\"Adding node under parent id {parent_id}.\")\n",
        "            else:\n",
        "                print(f\"Question out of context with parent id {parent_id}. Creating a new tree.\")\n",
        "                tree.append(new_node)\n",
        "        else:\n",
        "            print(f\"Warning: Parent with id {parent_id} not found. Adding as a new tree.\")\n",
        "            tree.append(new_node)\n",
        "    else:\n",
        "        tree.append(new_node)\n",
        "\n",
        "    # Write the updated tree back to the JSON file with pretty printing.\n",
        "    with open(file_path, 'w') as f:\n",
        "        json.dump(tree, f, indent=4)\n",
        "\n",
        "    return new_id\n",
        "\n",
        "# Test Cases to Demonstrate Subtree and New Tree Functionality\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"qa_tree.json\"\n",
        "\n",
        "    # Test Case 1: Add a root-level question.\n",
        "    root_id = update_json_tree(file_path,\n",
        "                               \"What is your favorite color?\",\n",
        "                               \"Blue\")\n",
        "    print(f\"Added root node with id: {root_id}\")\n",
        "\n",
        "    # Test Case 2: Add a child question under the root question (in context).\n",
        "    child1_id = update_json_tree(file_path,\n",
        "                                 \"Why do you like that color?\",\n",
        "                                 \"It is calming and reminiscent of the sky.\",\n",
        "                                 parent_id=root_id)\n",
        "    print(f\"Added child node with id: {child1_id} under parent id: {root_id}\")\n",
        "\n",
        "    # Test Case 3: Add a new question that is out of context with the current tree.\n",
        "    new_tree_id = update_json_tree(file_path,\n",
        "                                   \"What is your favourite sport?\",\n",
        "                                   \"I enjoy playing soccer.\",\n",
        "                                   parent_id=root_id)  # Context check should fail, creating a new tree.\n",
        "    print(f\"Added node with id: {new_tree_id} as a new tree due to context change from parent id: {root_id}\")\n",
        "\n",
        "    # Test Case 4: Add another child in context under the first child question.\n",
        "    grandchild_id = update_json_tree(file_path,\n",
        "                                     \"Could you elaborate on how the color affects your mood?\",\n",
        "                                     \"It creates a soothing ambiance.\",\n",
        "                                     parent_id=child1_id)\n",
        "    print(f\"Added grandchild node with id: {grandchild_id} under parent id: {child1_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aPJ0dSLgCqyY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import uuid\n",
        "import re\n",
        "\n",
        "# Define a set of common English stopwords to filter out during tokenization.\n",
        "STOPWORDS = {\n",
        "    \"what\", \"is\", \"your\", \"a\", \"an\", \"the\", \"and\", \"or\", \"but\", \"if\",\n",
        "    \"of\", \"for\", \"to\", \"in\", \"with\", \"on\", \"at\", \"from\", \"as\", \"it\",\n",
        "    \"are\", \"this\", \"that\", \"was\", \"were\", \"be\", \"been\", \"has\", \"have\", \"had\"\n",
        "}\n",
        "\n",
        "def find_node_by_id(nodes, node_id):\n",
        "    \"\"\"\n",
        "    Recursively searches for a node with the given node_id in a list of nodes.\n",
        "    \"\"\"\n",
        "    for node in nodes:\n",
        "        if node['id'] == node_id:\n",
        "            return node\n",
        "        found = find_node_by_id(node.get('children', []), node_id)\n",
        "        if found:\n",
        "            return found\n",
        "    return None\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenizes the input text into a set of lower-case words, removing punctuation\n",
        "    and filtering out common stopwords.\n",
        "    \"\"\"\n",
        "    tokens = set(re.findall(r'\\w+', text.lower()))\n",
        "    filtered_tokens = {token for token in tokens if token not in STOPWORDS}\n",
        "    return filtered_tokens\n",
        "\n",
        "def is_in_context(new_question, parent_node, threshold=0.2):\n",
        "    \"\"\"\n",
        "    Determines whether the new question is contextually relevant to the parent's content.\n",
        "    \"\"\"\n",
        "    parent_text = parent_node.get('question', '') + \" \" + parent_node.get('answer', '')\n",
        "    new_tokens = tokenize(new_question)\n",
        "    parent_tokens = tokenize(parent_text)\n",
        "\n",
        "    if not new_tokens:\n",
        "        return False  # Avoid division by zero\n",
        "\n",
        "    common_tokens = new_tokens.intersection(parent_tokens)\n",
        "    ratio = len(common_tokens) / len(new_tokens)\n",
        "\n",
        "    return ratio >= threshold\n",
        "\n",
        "def update_qa_json(file_path, question, answer, parent_id=None):\n",
        "    \"\"\"\n",
        "    Updates the qa_json file with a new question-answer pair.\n",
        "    \"\"\"\n",
        "    if os.path.exists(file_path):\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                tree = json.load(f)\n",
        "                if not isinstance(tree, list):\n",
        "                    tree = []\n",
        "        except json.JSONDecodeError:\n",
        "            tree = []\n",
        "    else:\n",
        "        tree = []\n",
        "\n",
        "    new_id = str(uuid.uuid4())\n",
        "    new_node = {\n",
        "        \"id\": new_id,\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"children\": []\n",
        "    }\n",
        "\n",
        "    if parent_id is not None:\n",
        "        parent_node = find_node_by_id(tree, parent_id)\n",
        "        if parent_node:\n",
        "            if is_in_context(question, parent_node):\n",
        "                parent_node.setdefault(\"children\", []).append(new_node)\n",
        "            else:\n",
        "                tree.append(new_node)\n",
        "        else:\n",
        "            tree.append(new_node)\n",
        "    else:\n",
        "        tree.append(new_node)\n",
        "\n",
        "    with open(file_path, 'w') as f:\n",
        "        json.dump(tree, f, indent=4)\n",
        "\n",
        "    return new_id\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"qa2_tree.json\"\n",
        "\n",
        "    # Add questions and answers one by one\n",
        "    root_id = update_qa_json(file_path, \"What is the capital of France?\", \"Paris\")\n",
        "    child_id = update_qa_json(file_path, \"What is the population of Paris?\", \"Approximately 2.1 million\", root_id)\n",
        "    update_qa_json(file_path, \"What is the weather like in Paris?\", \"Variable, check a weather app\", child_id)\n",
        "    update_qa_json(file_path, \"What is the capital of Germany?\", \"Berlin\") #new root\n",
        "    update_qa_json(file_path, \"What is the capital of Spain?\", \"Madrid\") #new root\n",
        "    update_qa_json(file_path, \"what is the best food in paris?\", \"French food is generally considered excellent.\", child_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "agent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
